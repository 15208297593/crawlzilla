#!/bin/bash
bin=`dirname "$0"`
bin=`cd "$bin"; pwd`
cd $bin
# export path
. ../conf/crawlzilla-env.sh

function nutch_crawl_job(){
    # nutch crawl
    s_time=`date '+%s'`
    mkdir -p $CRAWLDB/$crawl_DB_name/meta/
    echo $s_time > $CRAWLDB/$crawl_DB_name/meta/start_time
    cp -r $URLS $CRAWLDB/$crawl_DB_name/meta
    show_echo "$NUTCH_HOME/bin/nutch crawl $URLS -dir $CRAWLDB/$crawl_DB_name -depth $depth -topN 5000"
    echo "$NUTCH_HOME/bin/nutch crawl $URLS -dir $CRAWLDB/$crawl_DB_name -depth $depth -topN 5000" >> /tmp/log
    $NUTCH_HOME/bin/nutch crawl $URLS -dir $CRAWLDB/$crawl_DB_name -depth $depth -topN 5000
    show_echo "nutch solr index ..."
    nutch_solr_index
    f_time=`date '+%s'`
    echo $f_time > $CRAWLDB/$crawl_DB_name/meta/finish_time

}

function nutch_solr_index(){
    ## add solr collection
    # cp collection
    cp -r $SOLR_HOME/example/solr/collection1 $SOLR_HOME/example/solr/$crawl_DB_name
    # add describe to solr.xml
    # sed -i ...
    insertLineNO=`cat -n /opt/crawlzilla/solr/example/solr/solr.xml | grep crawlzilla_end | awk 'NR==1 {print "" $1}'`
    insertLineNO=$(($insertLineNO-1))
    show_echo $insertLineNO

    Solr_Str="<core schema=\"schema.xml\" instanceDir="$crawl_DB_name/" name="$crawl_DB_name" config=\"solrconfig.xml\" dataDir=\"data\"/>"

    sed -i ''$insertLineNO'a  <core schema=\"schema.xml\" instanceDir="'$crawl_DB_name'/" name="'$crawl_DB_name'" config=\"solrconfig.xml\" dataDir=\"data\"/> ' $SOLR_HOME/example/solr/solr.xml
    show_echo "sed -i ''$insertLineNO'a '$Solr_Str'' $SOLR_HOME/example/solr/solr.xml"

    # run..
    show_echo "/bin/nutch solrindex http://127.0.0.1:8983/solr/$crawl_DB_name $CRAWLDB$crawl_DB_name/crawldb -linkdb $CRAWLDB$crawl_DB_name/linkdb $CRAWLDB$crawl_DB_name/segments/*"
        
   # restart solr 
    $bin/services solr restart

   echo "$NUTCH_HOME/bin/nutch solrindex http://127.0.0.1:8983/solr/$crawl_DB_name $CRAWLDB$crawl_DB_name/crawldb -linkdb $CRAWLDB$crawl_DB_name/linkdb $CRAWLDB$crawl_DB_name/segments/*"  >> /tmp/log
   $NUTCH_HOME/bin/nutch solrindex http://127.0.0.1:8983/solr/$crawl_DB_name $CRAWLDB/$crawl_DB_name/crawldb -linkdb $CRAWLDB/$crawl_DB_name/linkdb $CRAWLDB/$crawl_DB_name/segments/*
}

# create webmanager of crawlzilla

# delete search engine
function delete_search(){
  show_echo "delete"
  # sed solr.xml
  # crawlDB
}

function main(){
  case $1 in
    "crawljob")
        show_echo "crawljob"
        crawl_DB_name=$2
        depth=$3
        if [ "$crawl_DB_name" != "" ] && [ "$depth" != "" ] ; then
	   nutch_crawl_job $crawl_DB_name $depth
        else
            show_echo "Please key in crawl DB name and depth!"
        fi
    ;;
    "delete")
        show_echo "delete search engine: $2"
        DB_name=$2
    ;;
  *)
    show_echo "Welcome to Use CrawlJob Shell!"
    show_echo "Usage: crawljob DBName depth"
    exit 1
  esac
}

main $1 $2 $3
#nutch_solr_index
